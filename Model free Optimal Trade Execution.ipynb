{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Neural Network\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        inputDim = 2\n",
    "        hiddenWidth = 5\n",
    "        outputDim = 1\n",
    "    \n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(inputDim, hiddenWidth)\n",
    "        self.fc2 = nn.Linear(hiddenWidth, hiddenWidth)\n",
    "        self.fc3 = nn.Linear(hiddenWidth, hiddenWidth)\n",
    "        self.fc_out = nn.Linear(hiddenWidth, outputDim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        # activation function \n",
    "        x = torch.tanh(x)\n",
    "        # for monte carlo samples, dropout rate is not necessary\n",
    "        #x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = torch.tanh(x)\n",
    "        #x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = torch.tanh(x)\n",
    "        #x = self.dropout(x)\n",
    "    \n",
    "        x = self.fc_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters of the model\n",
    "\n",
    "# Set time_steps \n",
    "T = 1\n",
    "N = 100\n",
    "dt = float(T) / N\n",
    "t_array = np.linspace(0,T,N+1)\n",
    "\n",
    "# parameters\n",
    "b = 0.01\n",
    "sigma = 0.1\n",
    "k = 0.01\n",
    "A = 0.01\n",
    "phi = 0.007\n",
    "\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_gpu(i=0):  #@save\n",
    "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# paths:  torch.Tensor of shape (batch_size, N+1, dim)\n",
    "net = Net()\n",
    "net = net.to(device=try_gpu())\n",
    "print_every_n_steps = 1000\n",
    "\n",
    "dim = 1\n",
    "objective = []\n",
    "learning_steps = 100000\n",
    "\n",
    "# Adam, lr = 0.0005\n",
    "optimizer = optim.Adam(net.parameters(),lr=0.0005)\n",
    "\n",
    "for it in range(learning_steps):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    # Initialize \n",
    "    ones = torch.ones(batch_size, 1, dim, device=try_gpu()) # (batch_size, length of path, dim)\n",
    "    Q = ones * 1 # tensor with shape (batch_size, 1, dim)\n",
    "    S = ones * 20\n",
    "    X = ones * 0\n",
    "    \n",
    "    # path \n",
    "    for id_t, t in enumerate(t_array):\n",
    "        # Euler scheme\n",
    "        dW = torch.randn(batch_size, dim,device=try_gpu()) * np.sqrt(dt) # tensor with shape (batch_size, dim)\n",
    "        tt = torch.ones(batch_size, 1,device=try_gpu()) * t\n",
    "        inputs = torch.cat((tt, Q[:,-1,:]), 1) # tensor with shape (batch_size, 2)\n",
    "        v_t = net(inputs)\n",
    "        \n",
    "        Q_new = Q[:,-1,:] - v_t * dt # Q_new has shape (batch_size, dim)\n",
    "        S_new = S[:,-1,:] - b * v_t * dt + sigma * dW\n",
    "        X_new = X[:,-1,:] + v_t * (S[:,-1,:] - k * v_t) * dt\n",
    "        \n",
    "        Q = torch.cat((Q, Q_new.unsqueeze(1)), 1) #shape (batch_size, 1, dim)\n",
    "        S = torch.cat((S, S_new.unsqueeze(1)), 1)\n",
    "        X = torch.cat((X, X_new.unsqueeze(1)), 1)\n",
    "        \n",
    "    J = 0\n",
    "    for item in range(batch_size):\n",
    "        J += X[item,-1,:] + Q[item,-1,:]*S[item,-1,:] - A*Q[item,-1,:]**2 - phi*torch.sum(Q[item,:-1,0]**2*dt)\n",
    "    J =  - J / batch_size\n",
    "    \n",
    "    objective.append(-J.item())\n",
    "    # update theta\n",
    "    J.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if it % print_every_n_steps == 0:\n",
    "        print('step = ', it, ' loss = ', J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the objective function over iterations\n",
    "\n",
    "objective_function = [objective[i] for i in range(0,learning_steps,100)] # plot every 100 steps\n",
    "x = [i for i in range(0,learning_steps,100)]\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(13,5))\n",
    "ax.plot(x,objective_function,\"o--\",markersize=2)\n",
    "ax.set_title(\"Objective function over iteration (mini-batch size 256)\")\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Objective function\")\n",
    "\n",
    "plt.ylim(19.95,20.03)\n",
    "plt.show()\n",
    "#fig.savefig('minibatch256.jpg')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained neural networks to calculate optimal controls/ inventory / cash processes\n",
    "\n",
    "ones = torch.ones(batch_size, 1, dim) # (batch_size, length of path, dim)\n",
    "Q = ones * 1 # tensor with shape (batch_size, 1, dim)\n",
    "S = ones * 20\n",
    "X = ones * 0\n",
    "v = []\n",
    "    \n",
    "for id_t, t in enumerate(t_array):\n",
    "    # Euler scheme\n",
    "    dW = torch.randn(batch_size, dim,device=try_gpu()) * np.sqrt(dt)\n",
    "    tt = torch.ones(batch_size, 1) * t\n",
    "    inputs = torch.cat((tt, Q[:,-1,:]), 1) # tensor with shape (batch_size, 2)\n",
    "    v_t = net(inputs)\n",
    "    v.append(v_t)\n",
    "        \n",
    "    Q_new = Q[:,-1,:] - v_t * dt # Q_new has shape (batch_size, dim)\n",
    "    S_new = S[:,-1,:] - b * v_t * dt + sigma * dW\n",
    "    X_new = X[:,-1,:] + v_t * (S[:,-1,:] - k * v_t) * dt\n",
    "        \n",
    "    Q = torch.cat((Q, Q_new.unsqueeze(1)), 1)\n",
    "    S = torch.cat((S, S_new.unsqueeze(1)), 1)\n",
    "    X = torch.cat((X, X_new.unsqueeze(1)), 1)\n",
    "    \n",
    "    \n",
    "control = np.zeros([batch_size,len(t_array)])\n",
    "for i in range(len(t_array)):\n",
    "    control[:,i] = v[i].detach().numpy()[:,0]\n",
    "    \n",
    "\n",
    "inventory = Q[:,:-1,:].detach().numpy()\n",
    "cash = X[:,:-1,:].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learned controls\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "for i in range(batch_size):\n",
    "    ax.plot(t_array,control[i,:])\n",
    "    \n",
    "ax.set_title(\"Optimal trading speed from DNN\")\n",
    "ax.set_xlabel(\"T\")\n",
    "ax.set_ylabel(\"Trading speed\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the corresponding inventory process\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "for i in range(batch_size):\n",
    "    ax.plot(t_array,inventory[i,:,0])\n",
    "    \n",
    "ax.set_title(\"Inventory process from DNN\")\n",
    "ax.set_xlabel(\"T\")\n",
    "ax.set_ylabel(\"Inventory\")\n",
    "plt.show()\n",
    "\n",
    "#fig.savefig('change_alpha_trading.jpg')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the corresponding cash process\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "for i in range(batch_size):\n",
    "    plt.plot(t_array,cash[i,:,0])\n",
    "    \n",
    "ax.set_title(\"Cash process from DNN\")\n",
    "ax.set_xlabel(\"T\")\n",
    "ax.set_ylabel(\"Revenue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analytical solution of the optimal control\n",
    "\n",
    "gamma = np.sqrt(phi / k)\n",
    "epsilon = (A-0.5*b+np.sqrt(k*phi)) / (A-0.5*b-np.sqrt(k*phi))\n",
    "\n",
    "analytical_v = np.zeros([batch_size, len(t_array)-1])\n",
    "analytical_q = np.zeros([batch_size,len(t_array)])\n",
    "analytical_S = np.zeros([batch_size,len(t_array)])\n",
    "analytical_X = np.zeros([batch_size,len(t_array)])\n",
    "analytical_dW = np.sqrt(dt)*np.random.randn(batch_size,len(t_array)-1)\n",
    "\n",
    "analytical_q[:,0] = 1\n",
    "analytical_S[:,0] = 20\n",
    "analytical_X[:,0] = 0\n",
    "\n",
    "for i in range(len(t_array)-1):\n",
    "    t = i*dt\n",
    "    analytical_v[:,i] = analytical_q[:,i]*gamma*(epsilon*np.exp(gamma*(T-t))+np.exp(-gamma*(T-t))) / (epsilon*np.exp(gamma*(T-t))-np.exp(-gamma*(T-t)))\n",
    "    analytical_q[:,i+1] = analytical_q[:,i] - analytical_v[:,i]*dt\n",
    "    analytical_S[:,i+1] = analytical_S[:,i] - b*analytical_v[:,i]*dt + sigma*analytical_dW[:,i]\n",
    "    analytical_X[:,i+1] = analytical_X[:,i] + (analytical_S[:,i]-k*analytical_v[:,i])*analytical_v[:,i]*dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare learned control with  analytical solution  \n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "ax.plot(t_array,control[0,:],\"^\",markersize=3, label=\"Control from DNN\")\n",
    "ax.plot(t_array[:-1],analytical_v[0],label=\"Analytical solution\")\n",
    "\n",
    "ax.set_title(\"Optimal trading speed (alpha=0.01,phi=0.007)\")\n",
    "ax.set_xlabel(\"T\")\n",
    "ax.set_ylabel(\"Trading speed\")\n",
    "plt.legend()\n",
    "#fig.savefig('alpha001.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the error of learned controls with analytical solutions\n",
    "\n",
    "error = [np.abs(analytical_v[0,i]-control[0,i])   for i in range(len(analytical_v[0]))]\n",
    "print(\"error = \",LA.norm(error, np.inf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the inventory processes \n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "ax.plot(t_array,inventory[0,:,0],label=\"Control from DNN\")\n",
    "ax.plot(t_array,analytical_q[0],label=\"Analytical solution\")\n",
    "    \n",
    "ax.set_title(\"Inventory from DNN\")\n",
    "ax.set_xlabel(\"T\")\n",
    "ax.set_ylabel(\"Revenue\")\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
